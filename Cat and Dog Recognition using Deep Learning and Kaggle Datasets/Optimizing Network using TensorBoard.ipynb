{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat vs Dog Recognition from Images using Deep Learning, Keras and Microsoft Kaggle Dataset\n",
    "\n",
    "## Part 3: Optimizing Our Model using TensorBoard\n",
    "In this part, we will try to optimize our previous model in Part 2 using TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dense, Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pickle.load(open(\"features.pickle\", \"rb\"))\n",
    "y = pickle.load(open(\"labels.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Our Neural Network with Different Parameters for Analyzing Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-conv-0-dense-128-node\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 117s 161ms/step - loss: 0.6465 - accuracy: 0.6164 - val_loss: 0.5593 - val_accuracy: 0.7242\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 100s 142ms/step - loss: 0.5468 - accuracy: 0.7314 - val_loss: 0.5218 - val_accuracy: 0.7479\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 101s 144ms/step - loss: 0.4955 - accuracy: 0.7611 - val_loss: 0.5261 - val_accuracy: 0.7459\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 101s 145ms/step - loss: 0.4687 - accuracy: 0.7759 - val_loss: 0.5487 - val_accuracy: 0.7303\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 102s 145ms/step - loss: 0.4498 - accuracy: 0.7895 - val_loss: 0.5789 - val_accuracy: 0.7186\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 98s 139ms/step - loss: 0.4286 - accuracy: 0.7980 - val_loss: 0.5684 - val_accuracy: 0.7295\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 99s 141ms/step - loss: 0.4071 - accuracy: 0.8161 - val_loss: 0.5327 - val_accuracy: 0.7455\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 99s 141ms/step - loss: 0.3888 - accuracy: 0.8214 - val_loss: 0.5673 - val_accuracy: 0.7343\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 99s 141ms/step - loss: 0.3585 - accuracy: 0.8404 - val_loss: 0.5778 - val_accuracy: 0.7291\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 100s 143ms/step - loss: 0.3428 - accuracy: 0.8550 - val_loss: 0.5534 - val_accuracy: 0.7435\n",
      "1-conv-1-dense-128-node\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 132s 187ms/step - loss: 0.6856 - accuracy: 0.5962 - val_loss: 0.5662 - val_accuracy: 0.7110\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 129s 184ms/step - loss: 0.5417 - accuracy: 0.7321 - val_loss: 0.5329 - val_accuracy: 0.7523\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 129s 184ms/step - loss: 0.4895 - accuracy: 0.7620 - val_loss: 0.5547 - val_accuracy: 0.7303 ETA: 0s - loss: 0.4895 - accu\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 129s 184ms/step - loss: 0.4612 - accuracy: 0.7818 - val_loss: 0.6129 - val_accuracy: 0.6914\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 129s 184ms/step - loss: 0.4194 - accuracy: 0.8067 - val_loss: 0.5296 - val_accuracy: 0.7355\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 129s 183ms/step - loss: 0.3745 - accuracy: 0.8322 - val_loss: 0.5646 - val_accuracy: 0.7311\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 129s 184ms/step - loss: 0.3371 - accuracy: 0.8493 - val_loss: 0.5913 - val_accuracy: 0.7343\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 133s 190ms/step - loss: 0.2887 - accuracy: 0.8775 - val_loss: 0.6326 - val_accuracy: 0.7242\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 131s 187ms/step - loss: 0.2382 - accuracy: 0.9029 - val_loss: 0.7101 - val_accuracy: 0.7178\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 131s 186ms/step - loss: 0.1932 - accuracy: 0.9250 - val_loss: 0.7587 - val_accuracy: 0.7182\n",
      "1-conv-2-dense-128-node\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 133s 188ms/step - loss: 0.6481 - accuracy: 0.6187 - val_loss: 0.5327 - val_accuracy: 0.7459\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 128s 182ms/step - loss: 0.5090 - accuracy: 0.7517 - val_loss: 0.5491 - val_accuracy: 0.7299\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 127s 182ms/step - loss: 0.4491 - accuracy: 0.7850 - val_loss: 0.5687 - val_accuracy: 0.7279\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 128s 182ms/step - loss: 0.3812 - accuracy: 0.8264 - val_loss: 0.5681 - val_accuracy: 0.7383\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 127s 181ms/step - loss: 0.2888 - accuracy: 0.8768 - val_loss: 0.6122 - val_accuracy: 0.7499\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 128s 182ms/step - loss: 0.1859 - accuracy: 0.9264 - val_loss: 0.8064 - val_accuracy: 0.7106\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 130s 186ms/step - loss: 0.1230 - accuracy: 0.9522 - val_loss: 0.9103 - val_accuracy: 0.7114\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 128s 182ms/step - loss: 0.0717 - accuracy: 0.9749 - val_loss: 1.1403 - val_accuracy: 0.7078\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 129s 184ms/step - loss: 0.0635 - accuracy: 0.9774 - val_loss: 1.4314 - val_accuracy: 0.7178\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 127s 181ms/step - loss: 0.0524 - accuracy: 0.9833 - val_loss: 1.3992 - val_accuracy: 0.7246\n",
      "2-conv-0-dense-128-node\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 260s 369ms/step - loss: 0.6480 - accuracy: 0.6018 - val_loss: 0.5221 - val_accuracy: 0.7559\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 256s 364ms/step - loss: 0.5095 - accuracy: 0.7463 - val_loss: 0.4860 - val_accuracy: 0.7752\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 256s 365ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.4756 - val_accuracy: 0.7816\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 258s 368ms/step - loss: 0.4311 - accuracy: 0.8016 - val_loss: 0.4999 - val_accuracy: 0.7699\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 260s 370ms/step - loss: 0.4014 - accuracy: 0.8182 - val_loss: 0.4581 - val_accuracy: 0.7896\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 258s 367ms/step - loss: 0.3629 - accuracy: 0.8422 - val_loss: 0.5158 - val_accuracy: 0.7655\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 258s 368ms/step - loss: 0.3400 - accuracy: 0.8530 - val_loss: 0.4277 - val_accuracy: 0.8024\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 258s 367ms/step - loss: 0.3092 - accuracy: 0.8658 - val_loss: 0.4511 - val_accuracy: 0.7952\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 258s 368ms/step - loss: 0.2820 - accuracy: 0.8784 - val_loss: 0.4256 - val_accuracy: 0.8120\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 257s 367ms/step - loss: 0.2700 - accuracy: 0.8869 - val_loss: 0.5065 - val_accuracy: 0.7836\n",
      "2-conv-1-dense-128-node\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 261s 370ms/step - loss: 0.6586 - accuracy: 0.5841 - val_loss: 0.5853 - val_accuracy: 0.7138\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 258s 368ms/step - loss: 0.5276 - accuracy: 0.7414 - val_loss: 0.5086 - val_accuracy: 0.7559\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 259s 369ms/step - loss: 0.4604 - accuracy: 0.7822 - val_loss: 0.4748 - val_accuracy: 0.7727\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 263s 375ms/step - loss: 0.4207 - accuracy: 0.8056 - val_loss: 0.4991 - val_accuracy: 0.7475\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 257s 366ms/step - loss: 0.3831 - accuracy: 0.8235 - val_loss: 0.4404 - val_accuracy: 0.7988\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 257s 367ms/step - loss: 0.3419 - accuracy: 0.8525 - val_loss: 0.4540 - val_accuracy: 0.7976\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 258s 368ms/step - loss: 0.3013 - accuracy: 0.8721 - val_loss: 0.4769 - val_accuracy: 0.7892\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 258s 368ms/step - loss: 0.2531 - accuracy: 0.8938 - val_loss: 0.4875 - val_accuracy: 0.7932\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 257s 367ms/step - loss: 0.2110 - accuracy: 0.9150 - val_loss: 0.5399 - val_accuracy: 0.7928\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 257s 366ms/step - loss: 0.1644 - accuracy: 0.9353 - val_loss: 0.5842 - val_accuracy: 0.7840\n",
      "2-conv-2-dense-128-node\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 260s 370ms/step - loss: 0.6714 - accuracy: 0.5617 - val_loss: 0.5737 - val_accuracy: 0.7174\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 256s 365ms/step - loss: 0.5463 - accuracy: 0.7227 - val_loss: 0.4898 - val_accuracy: 0.7699\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 258s 367ms/step - loss: 0.4658 - accuracy: 0.7795 - val_loss: 0.4753 - val_accuracy: 0.7699\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 260s 370ms/step - loss: 0.4214 - accuracy: 0.8031 - val_loss: 0.4676 - val_accuracy: 0.7892\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 257s 366ms/step - loss: 0.3714 - accuracy: 0.8346 - val_loss: 0.4710 - val_accuracy: 0.7832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "702/702 [==============================] - 255s 363ms/step - loss: 0.3229 - accuracy: 0.8570 - val_loss: 0.4667 - val_accuracy: 0.7944\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 254s 362ms/step - loss: 0.2715 - accuracy: 0.8810 - val_loss: 0.4987 - val_accuracy: 0.7964\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 255s 364ms/step - loss: 0.2191 - accuracy: 0.9073 - val_loss: 0.6267 - val_accuracy: 0.7820\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 254s 362ms/step - loss: 0.1801 - accuracy: 0.9246 - val_loss: 0.6509 - val_accuracy: 0.7916\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 254s 362ms/step - loss: 0.1309 - accuracy: 0.9473 - val_loss: 0.8069 - val_accuracy: 0.7655\n",
      "3-conv-0-dense-128-node\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 283s 402ms/step - loss: 0.6536 - accuracy: 0.6005 - val_loss: 0.5242 - val_accuracy: 0.7507\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 279s 397ms/step - loss: 0.5009 - accuracy: 0.7571 - val_loss: 0.4675 - val_accuracy: 0.7824\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 281s 400ms/step - loss: 0.4353 - accuracy: 0.7966 - val_loss: 0.4508 - val_accuracy: 0.7948\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 280s 400ms/step - loss: 0.3830 - accuracy: 0.8281 - val_loss: 0.4144 - val_accuracy: 0.8116\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 281s 400ms/step - loss: 0.3446 - accuracy: 0.8485 - val_loss: 0.3999 - val_accuracy: 0.8208\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 281s 400ms/step - loss: 0.3097 - accuracy: 0.8635 - val_loss: 0.3816 - val_accuracy: 0.8349\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 280s 399ms/step - loss: 0.2610 - accuracy: 0.8892 - val_loss: 0.3897 - val_accuracy: 0.8405\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 280s 399ms/step - loss: 0.2233 - accuracy: 0.9060 - val_loss: 0.4412 - val_accuracy: 0.8176\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 279s 397ms/step - loss: 0.1862 - accuracy: 0.9254 - val_loss: 0.4499 - val_accuracy: 0.8144\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 280s 398ms/step - loss: 0.1574 - accuracy: 0.9383 - val_loss: 0.4400 - val_accuracy: 0.8265\n",
      "3-conv-1-dense-128-node\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 283s 401ms/step - loss: 0.6870 - accuracy: 0.5314 - val_loss: 0.6268 - val_accuracy: 0.6533\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 278s 396ms/step - loss: 0.5846 - accuracy: 0.6940 - val_loss: 0.5153 - val_accuracy: 0.7439\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 291s 414ms/step - loss: 0.4975 - accuracy: 0.7584 - val_loss: 0.5432 - val_accuracy: 0.7439\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 381s 543ms/step - loss: 0.4318 - accuracy: 0.8033 - val_loss: 0.4377 - val_accuracy: 0.8008\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 310s 442ms/step - loss: 0.3816 - accuracy: 0.8291 - val_loss: 0.4096 - val_accuracy: 0.8104\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 317s 452ms/step - loss: 0.3465 - accuracy: 0.8451 - val_loss: 0.3999 - val_accuracy: 0.8240\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 311s 443ms/step - loss: 0.3136 - accuracy: 0.8629 - val_loss: 0.3991 - val_accuracy: 0.8224\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 316s 450ms/step - loss: 0.2764 - accuracy: 0.8803 - val_loss: 0.4471 - val_accuracy: 0.8172\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 316s 450ms/step - loss: 0.2384 - accuracy: 0.9000 - val_loss: 0.4169 - val_accuracy: 0.8220\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 345s 492ms/step - loss: 0.2067 - accuracy: 0.9127 - val_loss: 0.4752 - val_accuracy: 0.8072\n",
      "3-conv-2-dense-128-node\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 342s 476ms/step - loss: 0.6805 - accuracy: 0.5489 - val_loss: 0.6132 - val_accuracy: 0.6729\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 332s 473ms/step - loss: 0.5562 - accuracy: 0.7153 - val_loss: 0.6122 - val_accuracy: 0.6870\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 354s 504ms/step - loss: 0.4540 - accuracy: 0.7849 - val_loss: 0.4841 - val_accuracy: 0.7719\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 333s 475ms/step - loss: 0.3955 - accuracy: 0.8195 - val_loss: 0.4378 - val_accuracy: 0.7960\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 315s 449ms/step - loss: 0.3572 - accuracy: 0.8422 - val_loss: 0.4136 - val_accuracy: 0.8164\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 285s 405ms/step - loss: 0.3058 - accuracy: 0.8643 - val_loss: 0.3963 - val_accuracy: 0.8212\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 284s 405ms/step - loss: 0.2681 - accuracy: 0.8858 - val_loss: 0.4029 - val_accuracy: 0.8273\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 284s 405ms/step - loss: 0.2250 - accuracy: 0.9052 - val_loss: 0.4626 - val_accuracy: 0.8144\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 283s 403ms/step - loss: 0.1839 - accuracy: 0.9257 - val_loss: 0.4535 - val_accuracy: 0.8285\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 283s 403ms/step - loss: 0.1441 - accuracy: 0.9413 - val_loss: 0.5081 - val_accuracy: 0.8273\n"
     ]
    }
   ],
   "source": [
    "# nodes_per_layer = [32, 64, 128]\n",
    "nodes_per_layer = [128]\n",
    "number_of_conv_layers = 3\n",
    "number_of_dense_layers = 3\n",
    "current_time = time.localtime(time.time())\n",
    "current_time_dir = \"{}-{}-{}-{}-{}-{}\".format(\n",
    "    current_time.tm_mday, current_time.tm_mon, current_time.tm_year, \n",
    "    current_time.tm_hour, current_time.tm_min, current_time.tm_sec\n",
    ")\n",
    "\n",
    "for nodes in nodes_per_layer:\n",
    "#     for conv_layer in range(1, number_of_conv_layers+1):\n",
    "    for conv_layer in range(1, number_of_conv_layers+1):\n",
    "        for dense_layer in range(number_of_dense_layers):\n",
    "            \n",
    "            #TensorBoard Logs\n",
    "            NAME = \"{}-conv-{}-dense-{}-node\".format(\n",
    "                conv_layer, dense_layer, nodes\n",
    "            )\n",
    "            print(NAME)\n",
    "            tensorboard = TensorBoard(log_dir='logs/{}/{}'.format(current_time_dir, NAME))\n",
    "            \n",
    "            #Neural Network\n",
    "            network = Sequential()\n",
    "            \n",
    "            #Adding Initial Block to the Network\n",
    "            network.add(Conv2D(nodes, (3, 3), input_shape=X.shape[1:]))\n",
    "            network.add(Activation('relu'))\n",
    "            network.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "            #n-1 Blocks of Conv2D Layer in the Network\n",
    "            for conv in range(conv_layer-1):\n",
    "                network.add(Conv2D(nodes, (3, 3)))\n",
    "                network.add(Activation('relu'))\n",
    "                network.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "            #Flatten the Layers\n",
    "            network.add(Flatten())\n",
    "\n",
    "            #n Blocks of Dense Layer in the Network\n",
    "            for dense in range(dense_layer):\n",
    "                network.add(Dense(64))\n",
    "                network.add(Activation('relu'))\n",
    "\n",
    "            #Output Layer\n",
    "            network.add(Dense(1))\n",
    "            network.add(Activation('sigmoid'))\n",
    "            \n",
    "            #Network Compile and Train\n",
    "            network.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            network.fit(X, y, batch_size=32, epochs=10, validation_split=0.1, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the training for several different parameters, We can see from TensorBoard Dashboard that The neural network is performs the most using 128 nodes in each layers with 3 Convulational and 0 Dense Layers.\n",
    "\n",
    "**Parameters Used for Testing:**\n",
    "- Nodes Per Layer: 32, 64, 128\n",
    "- Number of Convolutional Layers: 1, 2, 3\n",
    "- Number of Dense Layers: 0, 1, 2\n",
    "\n",
    "**Best Parameters Found:**\n",
    "- Nodes Per Layer: 128\n",
    "- Number of Convolutional Layers: 3\n",
    "- Number of Dense Layers: 0\n",
    "- Number of Epochs: 7\n",
    "\n",
    "Now we will go back to our Part-2 and finally train our neural network using the best parameters for the most optimal result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
